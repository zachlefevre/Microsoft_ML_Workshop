{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a jupyter notebook. You can selectively run any cell by selecting the cell and clicking **run**  \n",
    "(optional) Install Jupyter with:  \n",
    "```pip install jupyter```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install NumPy:  \n",
    "    ```pip install numpy```  \n",
    "Install Keras:  \n",
    "    ```pip install keras```  \n",
    "Install Matplotlib:  \n",
    "    ```pip install matplotlib```  \n",
    "Install CNTK:  \n",
    "    1) Go to [The CNTK docs](https://docs.microsoft.com/en-us/cognitive-toolkit/setup-windows-python?tabs=cntkpy22)  \n",
    "    2) Find the library which matches your python installation, and computer architecture  \n",
    "    3) ```pip install <given url>```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open **cmd** and run **python**.  \n",
    "Type ```import keras```  \n",
    "You will receive errors. This is okay, we generating *%userprofile%\\\\.keras\\\\keras.json*  \n",
    "Open *%userprofile%\\\\.keras\\\\keras.json* and change the *backend* value to *cntk*  \n",
    "In your python console type ```import keras```. You should not receive errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import keras, matplotlib, and numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CNTK backend\n",
      "c:\\users\\zachl\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\cntk_backend.py:19: UserWarning: CNTK backend warning: GPU is not detected. CNTK's CPU version is not fully optimized,please run with GPU to get better performance.\n",
      "  'CNTK backend warning: GPU is not detected. '\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPool2D\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "import keras.backend as K\n",
    "import keras\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's choose a random number in the training data and display it with imshow.  \n",
    "Notice that I am graphing the X_train member to see the handwritten digit. Y_train is the corrsponding label to X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDwRF+IGgCD8QFOEHgvp/z+zXtYUPmnoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x248baff8f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "toShow = np.random.randint(len(X_train))\n",
    "plt.imshow(X_train[toShow], cmap='Greys')\n",
    "plt.show()\n",
    "print(Y_train[toShow])\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the X_train member is simply printed, The console will display a 28 x 28 array whose numbers are between 0 and 255.  \n",
    "0 represents the whitest white and 255 represents the blackest black. Any other number is some gray in between"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0 138 223   6   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    8 214 241   8   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  121 254 169   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  169 254 140   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  48   6   0  15\n",
      "  239 225  34   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   5  30 114 254  77   0 152\n",
      "  254 140   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 154 254 254 254 230  21 169\n",
      "  254  75   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  33 182 253 254 232  44   8   6 219\n",
      "  208   2   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  16 164 254 247 134  24   0   0  66 254\n",
      "  196   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 141 254 254  93   0   0   0  15 219 254\n",
      "  113   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 108 248 250  91   0   8 136 127 244 254 255\n",
      "  113   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  23 244 254 167  70 223 229 254 245 146 245 254\n",
      "   29   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 104 254 254 254 254 254 235 116  42  30 241 251\n",
      "   18   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  41 254 254 254 254 125  13   0   0 101 254 178\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   1  82 147 113  46   1   0   0   0 149 254 178\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 142 254 102\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  26 235 150\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 198 178\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 187 178\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  31 147\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[toShow])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin Setting up the model parameters with quantities that we alrady know.  \n",
    "Each image is 28x28, and there are 10 possible classes (labels): 0 .. 9  \n",
    "The batch size is a hyper parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows = 28\n",
    "img_cols = 28\n",
    "img_colors = 1\n",
    "num_classes = 10\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *image_data_format* attribute in the keras.json file specifies where the number of colors is represented in the image shape.  \n",
    "If *channels_first* is the value, then each image is an array of shape (img_colors, img_rows, img_cols).  \n",
    "If *channels_last* is the value, then each image is an array of shape (img_rows, img_cols, img_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_colors, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_colors, img_rows, img_cols)\n",
    "    img_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, img_colors)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, img_colors) \n",
    "    img_shape = (img_cols, img_rows, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure that our dataset is a sequence of floats, and that each number is between 0 and 1.  \n",
    "We are scaling our data set to be [0,1] inclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print out a training sample to see what it looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.5411765 ]\n",
      "  [ 0.87450981]\n",
      "  [ 0.02352941]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.03137255]\n",
      "  [ 0.8392157 ]\n",
      "  [ 0.94509804]\n",
      "  [ 0.03137255]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.47450981]\n",
      "  [ 0.99607843]\n",
      "  [ 0.66274512]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.66274512]\n",
      "  [ 0.99607843]\n",
      "  [ 0.54901963]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.1882353 ]\n",
      "  [ 0.02352941]\n",
      "  [ 0.        ]\n",
      "  [ 0.05882353]\n",
      "  [ 0.93725491]\n",
      "  [ 0.88235295]\n",
      "  [ 0.13333334]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.01960784]\n",
      "  [ 0.11764706]\n",
      "  [ 0.44705883]\n",
      "  [ 0.99607843]\n",
      "  [ 0.3019608 ]\n",
      "  [ 0.        ]\n",
      "  [ 0.59607846]\n",
      "  [ 0.99607843]\n",
      "  [ 0.54901963]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.60392159]\n",
      "  [ 0.99607843]\n",
      "  [ 0.99607843]\n",
      "  [ 0.99607843]\n",
      "  [ 0.90196079]\n",
      "  [ 0.08235294]\n",
      "  [ 0.66274512]\n",
      "  [ 0.99607843]\n",
      "  [ 0.29411766]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.12941177]\n",
      "  [ 0.71372551]\n",
      "  [ 0.99215686]\n",
      "  [ 0.99607843]\n",
      "  [ 0.90980393]\n",
      "  [ 0.17254902]\n",
      "  [ 0.03137255]\n",
      "  [ 0.02352941]\n",
      "  [ 0.85882354]\n",
      "  [ 0.81568629]\n",
      "  [ 0.00784314]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.0627451 ]\n",
      "  [ 0.64313728]\n",
      "  [ 0.99607843]\n",
      "  [ 0.96862745]\n",
      "  [ 0.52549022]\n",
      "  [ 0.09411765]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.25882354]\n",
      "  [ 0.99607843]\n",
      "  [ 0.76862746]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.5529412 ]\n",
      "  [ 0.99607843]\n",
      "  [ 0.99607843]\n",
      "  [ 0.36470589]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.05882353]\n",
      "  [ 0.85882354]\n",
      "  [ 0.99607843]\n",
      "  [ 0.44313726]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.42352942]\n",
      "  [ 0.97254902]\n",
      "  [ 0.98039216]\n",
      "  [ 0.35686275]\n",
      "  [ 0.        ]\n",
      "  [ 0.03137255]\n",
      "  [ 0.53333336]\n",
      "  [ 0.49803922]\n",
      "  [ 0.95686275]\n",
      "  [ 0.99607843]\n",
      "  [ 1.        ]\n",
      "  [ 0.44313726]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.09019608]\n",
      "  [ 0.95686275]\n",
      "  [ 0.99607843]\n",
      "  [ 0.65490198]\n",
      "  [ 0.27450982]\n",
      "  [ 0.87450981]\n",
      "  [ 0.89803922]\n",
      "  [ 0.99607843]\n",
      "  [ 0.96078432]\n",
      "  [ 0.57254905]\n",
      "  [ 0.96078432]\n",
      "  [ 0.99607843]\n",
      "  [ 0.11372549]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.40784314]\n",
      "  [ 0.99607843]\n",
      "  [ 0.99607843]\n",
      "  [ 0.99607843]\n",
      "  [ 0.99607843]\n",
      "  [ 0.99607843]\n",
      "  [ 0.92156863]\n",
      "  [ 0.45490196]\n",
      "  [ 0.16470589]\n",
      "  [ 0.11764706]\n",
      "  [ 0.94509804]\n",
      "  [ 0.98431373]\n",
      "  [ 0.07058824]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.16078432]\n",
      "  [ 0.99607843]\n",
      "  [ 0.99607843]\n",
      "  [ 0.99607843]\n",
      "  [ 0.99607843]\n",
      "  [ 0.49019608]\n",
      "  [ 0.05098039]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.39607844]\n",
      "  [ 0.99607843]\n",
      "  [ 0.69803923]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.00392157]\n",
      "  [ 0.32156864]\n",
      "  [ 0.57647061]\n",
      "  [ 0.44313726]\n",
      "  [ 0.18039216]\n",
      "  [ 0.00392157]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.58431375]\n",
      "  [ 0.99607843]\n",
      "  [ 0.69803923]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.55686277]\n",
      "  [ 0.99607843]\n",
      "  [ 0.40000001]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.10196079]\n",
      "  [ 0.92156863]\n",
      "  [ 0.58823532]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.7764706 ]\n",
      "  [ 0.69803923]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.73333335]\n",
      "  [ 0.69803923]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.12156863]\n",
      "  [ 0.57647061]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]\n",
      "\n",
      " [[ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]\n",
      "  [ 0.        ]]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[toShow])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to convert our Y_train members from scalars to one_hot representations of those numbers.  \n",
    "Ex:  \n",
    "    7 becomes [0,0,0,0,0,0,0,1,0,0]  \n",
    "    2 becomes [0,0,1,0,0,0,0,0,0,0]  \n",
    "Keras has a convenient function to doing exactly this.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "Y_train = np_utils.to_categorical(Y_train, num_classes)\n",
    "Y_test = np_utils.to_categorical(Y_test, num_classes)\n",
    "print(Y_train[toShow])\n",
    "print(Y_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution2D(32, kernel_size = (3,3),\n",
    "        activation='relu',\n",
    "        input_shape= img_shape))\n",
    "model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the standards of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = keras.losses.categorical_crossentropy,\n",
    "                    optimizer = keras.optimizers.Adadelta(),\n",
    "                    metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zachl\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\cntk\\core.py:361: UserWarning: your data is of type \"float64\", but your input variable (uid \"Input120\") expects \"<class 'numpy.float32'>\". Please convert your data beforehand to speed up training.\n",
      "  (sample.dtype, var.uid, str(var.dtype)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 608s - loss: 0.3280 - acc: 0.9003 - val_loss: 0.0804 - val_acc: 0.9755\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x248bb049780>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,\n",
    "    Y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs = 1,\n",
    "    verbose = 1,\n",
    "    validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the quality of our neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print(\"loss: \", score[0])\n",
    "print(\"accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
