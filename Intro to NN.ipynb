{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of ML\n",
    "There are several different type of machine learning. The easiest two understand as a beginner are:\n",
    "1. supervised\n",
    "    - data is labelled.\n",
    "2. unsupervised\n",
    "    - data is unlabelled.\n",
    "\n",
    "### Data\n",
    "All types of machine learning require data. That data is a numerical vector. **EVERYTHING** in ML are vectors/matrices. Inputs, outputs, weights, scores, gradients, losses, etc\n",
    "* If the neural network is operating on images of handwitten digits which are of the size 28 x 28, then the input vector will be a single 784 length vector whose elements represent how dark each pixel is.\n",
    "* If the neural network is operating on 8 movie scores, then the input vector is an 8 length input vector where each element is the rating of one movie\n",
    "\n",
    "The more data you have, the better your NN will perform. Usually.\n",
    "* The more examples of images of numbers you have, the better your NN will do.\n",
    "* The more complex each training example is, the more likely you will overfit your NN to the training data.\n",
    "    * Intuitively, if the data is unecessarily complex then the NN will make assumptions based on those properties that it shouldn't. If my images of handwritten digits also contain color, and 60% of the images of '4' are blue, then our NN will assume that the more blue an image is, the more likely it is a '4'\n",
    "    * More complex data also means larger input vectors. If an image is 28 x 28 and there are 3 colors, then the input vector is of size 28 \\* 28 \\* 3. **The larger your input vector, the more likely you will overfit your data**. (**The more complex your data, the more likely you will overfit your data**.)\n",
    "    \n",
    "    #### What is overfitting\n",
    "    An overfit neural network is one which does very well classifying data it was trained on, but does poorly on new data.  \n",
    "        * If our NN can classify with 99% accuracy an element of our training data set, but only performs with an accuracy of 50% on an image it has never seen, then our NN is overfit.\n",
    "        ##### How to prevent overfitting\n",
    "        We split our data set into two groups.\n",
    "        1. Training\n",
    "            * We train on this set (obviously). If our NN mistakes a '4' for an '8', then we change our NN to better classify this '4'.\n",
    "        2. Testing\n",
    "            * We **never** train on this set. If our NN mistakes a '4' for an '8', then we store that it got it wrong, and use this tally to calculate how well our NN did.\n",
    "            * As we train our NN, we will test that our scores for the testing set are not going down. The testing scores going down signifies that we are overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n",
      "[[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n"
     ]
    }
   ],
   "source": [
    "v = [1,2,3]\n",
    "m = [[1,2,3],\n",
    "     [4,5,6],\n",
    "     [7,8,9]]\n",
    "\n",
    "print(v)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the MNIST training set and testing set from [here](https://pjreddie.com/projects/mnist-in-csv/), and put the .csv in the same directory as this notebook.  \n",
    "The MNIST dataset contains examples of handwritten digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_file_ref = open(\"./mnist_train.csv\", 'r')\n",
    "training_data_set = training_data_file_ref.readlines();\n",
    "training_data_file_ref.close();\n",
    "\n",
    "testing_data_file_ref = open(\"./mnist_test.csv\", 'r')\n",
    "testing_data_set = testing_data_file_ref.readlines();\n",
    "testing_data_file_ref.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 60000 images\n",
      "5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,18,18,18,126,136,175,26,166,255,247,127,0,0,0,0,0,0,0,0,0,0,0,0,30,36,94,154,170,253,253,253,253,253,225,172,253,242,195,64,0,0,0,0,0,0,0,0,0,0,0,49,238,253,253,253,253,253,253,253,253,251,93,82,82,56,39,0,0,0,0,0,0,0,0,0,0,0,0,18,219,253,253,253,253,253,198,182,247,241,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,80,156,107,253,253,205,11,0,43,154,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,14,1,154,253,90,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,139,253,190,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,190,253,70,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,35,241,225,160,108,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,81,240,253,253,119,25,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,45,186,253,253,150,27,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,93,252,253,187,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,249,253,249,64,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,46,130,183,253,253,207,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,39,148,229,253,253,253,250,182,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,24,114,221,253,253,253,253,201,78,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,23,66,213,253,253,253,253,198,81,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,171,219,253,253,253,253,195,80,9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,55,172,226,253,253,253,253,244,133,11,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,136,253,253,253,212,135,132,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_example = training_data_set[0]\n",
    "print(\"There are\", len(training_data_set), \"images\")\n",
    "print(training_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any element of the training_data_set array is a 785 length array, where the 0th element is the label and the other 784 elements are a flattened image of a handwritten digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAADmVJREFUeJzt3X+MVPW5x/HPI4KoEIOyUGLxbtuo\nuYakWx1JDWL2UiXUNAGCNSWxoZF0G63JxRBTs39Yf+QaYi6tGE2T7QXBpLVUAcHEtCgx8ZJodfxV\nRdSqWcteEJaoVIjSAM/9Yw/NijvfGWbOzBn2eb8SszPnOd89jwMfzsx858zX3F0A4jmt6AYAFIPw\nA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8I6vRWHmzy5Mne2dnZykMCofT392v//v1Wy74Nhd/M\n5klaJWmMpP9x9xWp/Ts7O1Uulxs5JICEUqlU8751P+03szGSHpL0fUmXSFpsZpfU+/sAtFYjr/ln\nSnrP3T9w939K+oOk+fm0BaDZGgn/+ZJ2Dbs/kG37EjPrMbOymZUHBwcbOByAPDUS/pHeVPjK9cHu\n3ufuJXcvdXR0NHA4AHlqJPwDkqYPu/91SbsbawdAqzQS/pckXWhm3zCzcZJ+JGlLPm0BaLa6p/rc\n/YiZ3SLpzxqa6lvj7jty6wxAUzU0z+/uT0l6KqdeALQQH+8FgiL8QFCEHwiK8ANBEX4gKMIPBEX4\ngaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF\n+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gqIZW6TWzfkmfSToq6Yi7l/JoCvk5duxYsn748OGmHn/d\nunUVa4cOHUqOfeutt5L1+++/P1nv7e2tWHvwwQeTY88888xkfeXKlcn6TTfdlKy3g4bCn/kPd9+f\nw+8B0EI87QeCajT8Lmmrmb1sZj15NASgNRp92j/L3Xeb2RRJT5vZ2+7+3PAdsn8UeiTpggsuaPBw\nAPLS0Jnf3XdnP/dJ2iRp5gj79Ll7yd1LHR0djRwOQI7qDr+ZnW1mE4/fljRX0pt5NQaguRp52j9V\n0iYzO/57fu/uf8qlKwBNV3f43f0DSd/OsZdR68CBA8n60aNHk/XXX389Wd+6dWvF2qeffpoc29fX\nl6wXqbOzM1lfvnx5sr569eqKtXPOOSc5dvbs2cn6nDlzkvVTAVN9QFCEHwiK8ANBEX4gKMIPBEX4\ngaDyuKovvIGBgWS9q6srWf/kk0/ybOeUcdpp6XNPaqpOqn7Z7dKlSyvWpkyZkhw7YcKEZH00fFqV\nMz8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBMU8fw7OO++8ZH3q1KnJejvP88+dOzdZr/b/vnHjxoq1\nM844Izm2u7s7WUdjOPMDQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFDM8+eg2nXla9euTdYff/zxZP2K\nK65I1hctWpSsp1x55ZXJ+ubNm5P1cePGJesfffRRxdqqVauSY9FcnPmBoAg/EBThB4Ii/EBQhB8I\nivADQRF+IChz9/QOZmsk/UDSPnefkW07V9J6SZ2S+iVd7+5VL0ovlUpeLpcbbHn0OXz4cLJebS69\nt7e3Yu2+++5Ljn322WeT9auuuipZR3splUoql8tWy761nPnXSpp3wrbbJW1z9wslbcvuAziFVA2/\nuz8n6eMTNs+XtC67vU7Sgpz7AtBk9b7mn+rueyQp+5le+whA22n6G35m1mNmZTMrDw4ONvtwAGpU\nb/j3mtk0Scp+7qu0o7v3uXvJ3UujYXFDYLSoN/xbJC3Jbi+RlL70C0DbqRp+M3tU0vOSLjazATNb\nKmmFpGvM7G+SrsnuAziFVL2e390XVyh9L+dewqr2/fXVTJo0qe6xDzzwQLI+e/bsZN2spilltCE+\n4QcERfiBoAg/EBThB4Ii/EBQhB8Iiq/uHgWWLVtWsfbiiy8mx27atClZ37FjR7I+Y8aMZB3tizM/\nEBThB4Ii/EBQhB8IivADQRF+ICjCDwTFPP8okPpq776+vuTYbdu2Jevz589P1hcsSH9366xZsyrW\nFi5cmBzL5cLNxZkfCIrwA0ERfiAowg8ERfiBoAg/EBThB4KqukR3nliiu/1Uu95/3rwTF2j+sgMH\nDtR97DVr1iTrixYtStYnTJhQ97FHq7yX6AYwChF+ICjCDwRF+IGgCD8QFOEHgiL8QFBVr+c3szWS\nfiBpn7vPyLbdKemnkgaz3Xrd/almNYnmmTlzZrJe7Xv7b7311mT9scceq1i78cYbk2Pff//9ZP22\n225L1idOnJisR1fLmX+tpJE+6fFrd+/K/iP4wCmmavjd/TlJH7egFwAt1Mhr/lvM7K9mtsbMJuXW\nEYCWqDf8v5H0LUldkvZIWllpRzPrMbOymZUHBwcr7QagxeoKv7vvdfej7n5M0m8lVXzXyN373L3k\n7qWOjo56+wSQs7rCb2bTht1dKOnNfNoB0Cq1TPU9Kqlb0mQzG5D0S0ndZtYlySX1S/pZE3sE0ARc\nz4+GfPHFF8n6Cy+8ULF29dVXJ8dW+7t53XXXJevr169P1kcjrucHUBXhB4Ii/EBQhB8IivADQRF+\nICiW6EZDxo8fn6x3d3dXrI0ZMyY59siRI8n6E088kay/8847FWsXX3xxcmwEnPmBoAg/EBThB4Ii\n/EBQhB8IivADQRF+ICjm+ZG0e/fuZH3jxo3J+vPPP1+xVm0ev5rLL788Wb/ooosa+v2jHWd+ICjC\nDwRF+IGgCD8QFOEHgiL8QFCEHwiKef5RrtoSaQ899FCy/vDDDyfrAwMDJ91Trapd79/Z2Zmsm9X0\nDdZhceYHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaCqzvOb2XRJj0j6mqRjkvrcfZWZnStpvaROSf2S\nrnf3T5rXalwHDx5M1p988smKtbvvvjs59t13362rpzzMmTMnWV+xYkWyftlll+XZTji1nPmPSFru\n7v8u6buSfm5ml0i6XdI2d79Q0rbsPoBTRNXwu/sed38lu/2ZpJ2Szpc0X9K6bLd1khY0q0kA+Tup\n1/xm1inpO5L+Immqu++Rhv6BkDQl7+YANE/N4TezCZI2SFrm7v84iXE9ZlY2s3K1z5kDaJ2awm9m\nYzUU/N+5+/FvbNxrZtOy+jRJ+0Ya6+597l5y91JHR0cePQPIQdXw29ClUasl7XT3Xw0rbZG0JLu9\nRNLm/NsD0Cy1XNI7S9KPJb1hZq9l23olrZD0RzNbKunvkn7YnBZPfYcOHUrWd+3alazfcMMNyfqr\nr7560j3lZe7cucn6XXfdVbFW7au3uSS3uaqG3923S6r0p/C9fNsB0Cp8wg8IivADQRF+ICjCDwRF\n+IGgCD8QFF/dXaPPP/+8Ym3ZsmXJsdu3b0/W33777bp6ysO1116brN9xxx3JeldXV7I+duzYk+4J\nrcGZHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCCjPP39/fn6zfe++9yfozzzxTsfbhhx/W01Juzjrr\nrIq1e+65Jzn25ptvTtbHjRtXV09of5z5gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiCoMPP8GzZsSNZX\nr17dtGNfeumlyfrixYuT9dNPT/8x9fT0VKyNHz8+ORZxceYHgiL8QFCEHwiK8ANBEX4gKMIPBEX4\ngaDM3dM7mE2X9Iikr0k6JqnP3VeZ2Z2SfippMNu1192fSv2uUqnk5XK54aYBjKxUKqlcLlst+9by\nIZ8jkpa7+ytmNlHSy2b2dFb7tbv/d72NAihO1fC7+x5Je7Lbn5nZTknnN7sxAM11Uq/5zaxT0nck\n/SXbdIuZ/dXM1pjZpApjesysbGblwcHBkXYBUICaw29mEyRtkLTM3f8h6TeSviWpS0PPDFaONM7d\n+9y95O6ljo6OHFoGkIeawm9mYzUU/N+5+0ZJcve97n7U3Y9J+q2kmc1rE0DeqobfzEzSakk73f1X\nw7ZPG7bbQklv5t8egGap5d3+WZJ+LOkNM3st29YrabGZdUlySf2SftaUDgE0RS3v9m+XNNK8YXJO\nH0B74xN+QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoKp+\ndXeuBzMblPThsE2TJe1vWQMnp117a9e+JHqrV569/Zu71/R9eS0N/1cOblZ291JhDSS0a2/t2pdE\nb/Uqqjee9gNBEX4gqKLD31fw8VPatbd27Uuit3oV0luhr/kBFKfoMz+AghQSfjObZ2bvmNl7ZnZ7\nET1UYmb9ZvaGmb1mZoUuKZwtg7bPzN4ctu1cM3vazP6W/RxxmbSCervTzP4ve+xeM7NrC+ptupk9\na2Y7zWyHmf1ntr3Qxy7RVyGPW8uf9pvZGEnvSrpG0oCklyQtdve3WtpIBWbWL6nk7oXPCZvZVZIO\nSnrE3Wdk2+6T9LG7r8j+4Zzk7r9ok97ulHSw6JWbswVlpg1fWVrSAkk/UYGPXaKv61XA41bEmX+m\npPfc/QN3/6ekP0iaX0Afbc/dn5P08Qmb50tal91ep6G/PC1Xobe24O573P2V7PZnko6vLF3oY5fo\nqxBFhP98SbuG3R9Qey357ZK2mtnLZtZTdDMjmJotm358+fQpBfdzoqorN7fSCStLt81jV8+K13kr\nIvwjrf7TTlMOs9z9Uknfl/Tz7OktalPTys2tMsLK0m2h3hWv81ZE+AckTR92/+uSdhfQx4jcfXf2\nc5+kTWq/1Yf3Hl8kNfu5r+B+/qWdVm4eaWVptcFj104rXhcR/pckXWhm3zCzcZJ+JGlLAX18hZmd\nnb0RIzM7W9Jctd/qw1skLcluL5G0ucBevqRdVm6utLK0Cn7s2m3F60I+5JNNZdwvaYykNe7+Xy1v\nYgRm9k0Nne2loUVMf19kb2b2qKRuDV31tVfSLyU9IemPki6Q9HdJP3T3lr/xVqG3bg09df3Xys3H\nX2O3uLcrJf2vpDckHcs292ro9XVhj12ir8Uq4HHjE35AUHzCDwiK8ANBEX4gKMIPBEX4gaAIPxAU\n4QeCIvxAUP8PRZ8Vlgh2BcUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x264b464ebe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "training_example = training_example.split(',') #Split this huge string on commas.\n",
    "label = training_example[0] #The first element is the label\n",
    "training_example = np.asfarray(training_example[1:]).reshape((28,28)) #convert it to an array of floats of size 28 x 28\n",
    "\n",
    "print(label)\n",
    "plt.imshow(training_example, cmap='Greys')\n",
    "plt.show()\n",
    "print(training_example.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break down what our data set is:\n",
    "* A file containing 60,000 lines\n",
    "    * each line is a string\n",
    "        * each string is one training example, 785 characters long\n",
    "            * the first element of each training example is a label ('5', or '8', or some other label)\n",
    "                * the rest of the of the training example is a vector 784 characters long\n",
    "                     * each element of the vector represents the intensity of one pixel of a 28 x 28 image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks\n",
    "A NN is a pattern recognition device. A NN is used when the pattern being recognized is too complex to accomplish with traditional algorithms.\n",
    "* It trivial to recognize that 101 is 5 in binary. A NN is not necessary for this task.\n",
    "* It is simple to recognize a single image of a '5' and differentiate it from other numbers. A NN is not necessary for this task.\n",
    "* It is next to impossible to recognize thousands of images of '5's, and differentiate them from thousands of images of other numbers. A NN **is** necessary for this task.\n",
    "\n",
    "The output of the NN will be a vector representation of the \"confidence\" that the NN thinks an image matches the labels.\n",
    "* A NN which is 100% confident that it was given an image of '0' will output [1,0,0,0,0,0,0,0,0,0].\n",
    "* A NN which is 100% confident that it was given an image of '4' will output [0,0,0,0,1,0,0,0,0,0].\n",
    "* A NN which is 60% confident that it was given an image of '8', and 30% confident it was given an image of '1', and 10% confident that it was given an image of '3' will output [0, .3, 0, .1, 0, 0, 0, 0, .6, 0] \n",
    "\n",
    "**The output of a NN is a matrix of confidence scores.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A single Neuron\n",
    "\n",
    "A NN is a directed graph of neurons. A neuron is a node which has n inputs, 1 output, and some activation function.  \n",
    "All n inputs come into the neuron. Each input is weighted by some quantity, w1, ..., wn.  The weighted sum is calculated and passed to some activation function. The output of the activation function is the output of the neuron.\n",
    "![Single Neuron](imgs\\neuron_1.jpg)\n",
    "\n",
    "A 'vanilla' NN has 3 layers of neurons. The **input layer**, the **hidden layer**, and the **output layer**. Every neuron of the input layer is connected to every node of the hidden layer. Every node of the hidden layer is connected to every node of the output layer.\n",
    "\n",
    "![Artificial Neural Network](imgs\\ANN_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How it all relates to matrices (optional)\n",
    "The weights can be represented as a matrix of weights  \n",
    "[w11, w21, w31]  \n",
    "[w12, w22, w32]  \n",
    "[w13, w23, w33]  \n",
    "where each wij is the weight from the ith node in the previous layer to the jth node in the current layer.  \n",
    "If we multiply this weight matrix by the output of the previous layer, then apply the activation function to the resulting vector, we will have the output of the current layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.59]\n",
      " [ 0.87]\n",
      " [ 0.5 ]]\n"
     ]
    }
   ],
   "source": [
    "w = np.matrix([[.2,.6,.3],[.4,.7,.9],[.2,.3,.8]]) # The weights from the previous layer to the current layer\n",
    "i = np.matrix([.1,.8,.3]).T                 # The output of the previous layer, aka the input of the current layer\n",
    "o = w.dot(i)                                 # The product of these two matrices\n",
    "print(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Function\n",
    "The choice of activation function is very important. To mimick the way a neuron in the brain functions, we need something which is asymptotically limited to be between 0 and 1 for all inputs, and which will very quickly 'self-correct'. We will use the sigmoid function, which looks like this: \n",
    "![sigmoid function graph](imgs\\sigmoid.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.64336515]\n",
      " [ 0.7047457 ]\n",
      " [ 0.62245933]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import expit\n",
    "activated_o = expit(o)\n",
    "print(activated_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The activated_o is the final outut of this fake layer. This column vector would then be passed as input to the next layer where the process repeats.\n",
    "\n",
    "The number of inputs and outputs of a NN is evident in the problem. One of our images is a 784 length vector, therefore our NN will have 784 input neurons. The output of our NN is the classification of the image, i.e. '0', '1', ... '8', '9'.\n",
    "\n",
    "## NN from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self, input_nodes, hidden_nodes, output_nodes):\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "        \n",
    "        self.input_to_hidden_weights = np.random.normal(0.0, pow(self.hidden_nodes, -0.5), (self.hidden_nodes, self.input_nodes))\n",
    "        self.hidden_to_output_weights = np.random.normal(0.0, pow(self.output_nodes, -0.5), (self.output_nodes, self.hidden_nodes))\n",
    "    \n",
    "    def activate(self, x):\n",
    "        return expit(x)\n",
    "    \n",
    "    def query(self, input_list):\n",
    "        #convert input_list into a 2d array\n",
    "        input = np.array(input_list, ndmin=2).T\n",
    "        \n",
    "        hidden_input_signal = np.dot(self.input_to_hidden_weights, input)\n",
    "        hidden_output_signal = self.activate(hidden_input_signal)\n",
    "        output_input_signal = np.dot(self.hidden_to_output_weights, hidden_output_signal)\n",
    "        output_output_signal = self.activate(output_input_signal);\n",
    "        \n",
    "        return output_output_signal\n",
    "        \n",
    "    def shape(self):\n",
    "        return [self.input_nodes, self.hidden_nodes, self.output_nodes];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct answer:  5\n",
      "[[ 0.0023625 ]\n",
      " [ 0.05248763]\n",
      " [ 0.32015631]\n",
      " [ 0.14373562]\n",
      " [ 0.73034544]\n",
      " [ 0.73470512]\n",
      " [ 0.1500492 ]\n",
      " [ 0.81201532]\n",
      " [ 0.1236991 ]\n",
      " [ 0.98264315]]\n"
     ]
    }
   ],
   "source": [
    "num_input = 784\n",
    "num_hidden = 100\n",
    "num_output = 10\n",
    "\n",
    "NN = NeuralNetwork(num_input, num_hidden, num_output);\n",
    "\n",
    "\n",
    "training_example = np.asfarray(training_data_set[0].split(',')[1:])\n",
    "print(\"correct answer: \", training_data_set[0][0])\n",
    "print(NN.query(training_example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our NN has given a score! It is entirely completely wrong, and isn't normalized to be percentages, but it queried and that's all that really matters. Our NN is so far entirely untrained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "Training a NN is it's own art, philosophy, field of science and religion. I will give the basics.\n",
    "\n",
    "We must calculate how wrong we were.\n",
    "* The correct classification for '5' is [0,0,0,0,0,1,0,0,0,0], but our NN was entirely wrong. It gave the above vector. We must calculate the distance between these vectors. This distance however only tells us how incorrect the final output layer was, it tells us nothing about the hidden layer and the weights to it.\n",
    "    * We use **gradient descent** to attribute the responsibility of the final scores to each weight in the network\n",
    "        * If a weight is very high, like .8, and our output is very wrong, then we need to change the weight .8 much more than a very small weight.\n",
    "    * Once we have attributed responsibilit to certain weights, we perform **back propagation** to go backwards through the network and update the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork2:\n",
    "    \n",
    "    def __init__(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        self.input_to_hidden_weights = np.random.normal(0.0, pow(self.hidden_nodes, -0.5), (self.hidden_nodes, self.input_nodes))\n",
    "        self.hidden_to_output_weights = np.random.normal(0.0, pow(self.output_nodes, -0.5), (self.output_nodes, self.hidden_nodes))\n",
    "    \n",
    "    def activate(self, x):\n",
    "        return expit(x)\n",
    "\n",
    "    def train(self, input_list, target_list):\n",
    "        #convert input_list into a 2d array\n",
    "        input = np.array(input_list, ndmin=2).T\n",
    "        #convert target_list into a 2d array\n",
    "        target = np.array(target_list, ndmin=2).T\n",
    "        \n",
    "        #calculate signals in and out of hidden layers\n",
    "        hidden_input_signal = np.dot(self.input_to_hidden_weights, input)\n",
    "        hidden_output_signal = self.activate(hidden_input_signal)\n",
    "        \n",
    "        \n",
    "        output_input_signal = np.dot(self.hidden_to_output_weights, hidden_output_signal)\n",
    "        output_output_signal = self.activate(output_input_signal);\n",
    "        \n",
    "        output_error = target - output_output_signal\n",
    "        \n",
    "        hidden_error = np.dot(self.hidden_to_output_weights.T, output_error)\n",
    "        \n",
    "        self.hidden_to_output_weights += self.learning_rate * np.dot((output_error * output_output_signal * (1.0 - output_output_signal)), np.transpose(hidden_output_signal))\n",
    "        self.input_to_hidden_weights += self.learning_rate * np.dot((hidden_error * hidden_output_signal * (1-hidden_output_signal)), np.transpose(input))\n",
    "    \n",
    "    \n",
    "    def query(self, input_list):\n",
    "        #convert input_list into a 2d array\n",
    "        input = np.array(input_list, ndmin=2).T\n",
    "        \n",
    "        hidden_input_signal = np.dot(self.input_to_hidden_weights, input)\n",
    "        hidden_output_signal = self.activate(hidden_input_signal)\n",
    "        output_input_signal = np.dot(self.hidden_to_output_weights, hidden_output_signal)\n",
    "        output_output_signal = self.activate(output_input_signal);\n",
    "        \n",
    "        return output_output_signal\n",
    "        \n",
    "    def shape(self):\n",
    "        return [self.input_nodes, self.hidden_nodes, self.output_nodes];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n",
      "epoch:  1\n",
      "correct:  5 | estimated:  6 idx:  8\n",
      "correct:  7 | estimated:  1 idx:  111\n",
      "correct:  7 | estimated:  4 idx:  124\n",
      "correct:  2 | estimated:  9 idx:  149\n",
      "correct:  4 | estimated:  2 idx:  247\n",
      "correct:  8 | estimated:  1 idx:  257\n",
      "correct:  6 | estimated:  0 idx:  259\n",
      "correct:  8 | estimated:  4 idx:  290\n",
      "correct:  4 | estimated:  6 idx:  300\n",
      "correct:  9 | estimated:  7 idx:  320\n",
      "correct:  2 | estimated:  7 idx:  321\n",
      "correct:  5 | estimated:  3 idx:  340\n",
      "correct:  5 | estimated:  0 idx:  352\n",
      "correct:  2 | estimated:  7 idx:  362\n",
      "correct:  3 | estimated:  7 idx:  381\n",
      "correct:  2 | estimated:  8 idx:  444\n",
      "correct:  6 | estimated:  0 idx:  445\n",
      "correct:  9 | estimated:  3 idx:  479\n",
      "correct:  8 | estimated:  0 idx:  495\n",
      "correct:  8 | estimated:  3 idx:  543\n",
      "correct:  7 | estimated:  1 idx:  551\n",
      "correct:  4 | estimated:  9 idx:  565\n",
      "correct:  3 | estimated:  8 idx:  578\n",
      "correct:  8 | estimated:  1 idx:  582\n",
      "correct:  8 | estimated:  3 idx:  591\n",
      "correct:  7 | estimated:  9 idx:  605\n",
      "correct:  2 | estimated:  8 idx:  613\n",
      "correct:  3 | estimated:  9 idx:  628\n",
      "correct:  2 | estimated:  6 idx:  629\n",
      "correct:  7 | estimated:  4 idx:  658\n",
      "correct:  2 | estimated:  1 idx:  659\n",
      "correct:  8 | estimated:  4 idx:  691\n",
      "correct:  4 | estimated:  9 idx:  707\n",
      "correct:  0 | estimated:  6 idx:  717\n",
      "correct:  5 | estimated:  8 idx:  720\n",
      "correct:  4 | estimated:  9 idx:  740\n",
      "correct:  2 | estimated:  8 idx:  741\n",
      "correct:  4 | estimated:  9 idx:  760\n",
      "correct:  8 | estimated:  7 idx:  844\n",
      "correct:  4 | estimated:  9 idx:  881\n",
      "correct:  3 | estimated:  5 idx:  890\n",
      "correct:  1 | estimated:  3 idx:  900\n",
      "correct:  2 | estimated:  7 idx:  924\n",
      "correct:  2 | estimated:  8 idx:  926\n",
      "correct:  3 | estimated:  5 idx:  938\n",
      "correct:  2 | estimated:  0 idx:  939\n",
      "correct:  8 | estimated:  9 idx:  947\n",
      "correct:  7 | estimated:  2 idx:  950\n",
      "correct:  5 | estimated:  4 idx:  951\n",
      "correct:  1 | estimated:  6 idx:  956\n",
      "correct:  6 | estimated:  0 idx:  965\n",
      "correct:  5 | estimated:  3 idx:  1003\n",
      "correct:  7 | estimated:  9 idx:  1012\n",
      "correct:  6 | estimated:  5 idx:  1014\n",
      "correct:  5 | estimated:  8 idx:  1032\n",
      "correct:  7 | estimated:  9 idx:  1039\n",
      "correct:  6 | estimated:  8 idx:  1044\n",
      "correct:  3 | estimated:  9 idx:  1062\n",
      "correct:  8 | estimated:  4 idx:  1068\n",
      "correct:  5 | estimated:  8 idx:  1073\n",
      "correct:  9 | estimated:  3 idx:  1107\n",
      "correct:  4 | estimated:  6 idx:  1112\n",
      "correct:  3 | estimated:  8 idx:  1114\n",
      "correct:  7 | estimated:  9 idx:  1173\n",
      "correct:  6 | estimated:  1 idx:  1181\n",
      "correct:  9 | estimated:  4 idx:  1192\n",
      "correct:  7 | estimated:  9 idx:  1194\n",
      "correct:  8 | estimated:  4 idx:  1198\n",
      "correct:  3 | estimated:  8 idx:  1204\n",
      "correct:  7 | estimated:  2 idx:  1206\n",
      "correct:  7 | estimated:  2 idx:  1226\n",
      "correct:  9 | estimated:  4 idx:  1232\n",
      "correct:  4 | estimated:  9 idx:  1242\n",
      "correct:  9 | estimated:  3 idx:  1247\n",
      "correct:  2 | estimated:  5 idx:  1256\n",
      "correct:  7 | estimated:  1 idx:  1260\n",
      "correct:  4 | estimated:  9 idx:  1270\n",
      "correct:  7 | estimated:  2 idx:  1283\n",
      "correct:  5 | estimated:  9 idx:  1289\n",
      "correct:  5 | estimated:  7 idx:  1299\n",
      "correct:  8 | estimated:  3 idx:  1319\n",
      "correct:  7 | estimated:  1 idx:  1326\n",
      "correct:  7 | estimated:  9 idx:  1328\n",
      "correct:  5 | estimated:  3 idx:  1393\n",
      "correct:  2 | estimated:  6 idx:  1410\n",
      "correct:  4 | estimated:  8 idx:  1413\n",
      "correct:  4 | estimated:  9 idx:  1422\n",
      "correct:  8 | estimated:  4 idx:  1425\n",
      "correct:  8 | estimated:  1 idx:  1433\n",
      "correct:  4 | estimated:  9 idx:  1440\n",
      "correct:  5 | estimated:  3 idx:  1466\n",
      "correct:  5 | estimated:  9 idx:  1467\n",
      "correct:  7 | estimated:  9 idx:  1494\n",
      "correct:  7 | estimated:  1 idx:  1500\n",
      "correct:  7 | estimated:  9 idx:  1522\n",
      "correct:  5 | estimated:  0 idx:  1525\n",
      "correct:  1 | estimated:  6 idx:  1527\n",
      "correct:  8 | estimated:  7 idx:  1530\n",
      "correct:  4 | estimated:  6 idx:  1549\n",
      "correct:  9 | estimated:  3 idx:  1553\n",
      "correct:  7 | estimated:  9 idx:  1581\n",
      "correct:  2 | estimated:  6 idx:  1609\n",
      "correct:  4 | estimated:  7 idx:  1634\n",
      "correct:  5 | estimated:  8 idx:  1641\n",
      "correct:  2 | estimated:  0 idx:  1678\n",
      "correct:  3 | estimated:  7 idx:  1681\n",
      "correct:  9 | estimated:  3 idx:  1709\n",
      "correct:  7 | estimated:  1 idx:  1716\n",
      "correct:  8 | estimated:  0 idx:  1717\n",
      "correct:  2 | estimated:  4 idx:  1722\n",
      "correct:  7 | estimated:  2 idx:  1754\n",
      "correct:  7 | estimated:  6 idx:  1772\n",
      "correct:  2 | estimated:  8 idx:  1790\n",
      "correct:  2 | estimated:  3 idx:  1839\n",
      "correct:  8 | estimated:  9 idx:  1850\n",
      "correct:  6 | estimated:  4 idx:  1857\n",
      "correct:  8 | estimated:  3 idx:  1878\n",
      "correct:  8 | estimated:  3 idx:  1899\n",
      "correct:  9 | estimated:  4 idx:  1901\n",
      "correct:  5 | estimated:  0 idx:  1911\n",
      "correct:  4 | estimated:  6 idx:  1938\n",
      "correct:  7 | estimated:  2 idx:  1941\n",
      "correct:  9 | estimated:  3 idx:  1952\n",
      "correct:  8 | estimated:  1 idx:  1968\n",
      "correct:  5 | estimated:  3 idx:  1970\n",
      "correct:  8 | estimated:  3 idx:  1973\n",
      "correct:  2 | estimated:  0 idx:  1984\n",
      "correct:  7 | estimated:  2 idx:  2016\n",
      "correct:  7 | estimated:  9 idx:  2024\n",
      "correct:  5 | estimated:  3 idx:  2035\n",
      "correct:  4 | estimated:  8 idx:  2043\n",
      "correct:  2 | estimated:  7 idx:  2044\n",
      "correct:  4 | estimated:  9 idx:  2053\n",
      "correct:  7 | estimated:  9 idx:  2070\n",
      "correct:  5 | estimated:  0 idx:  2073\n",
      "correct:  8 | estimated:  1 idx:  2093\n",
      "correct:  2 | estimated:  0 idx:  2098\n",
      "correct:  3 | estimated:  7 idx:  2109\n",
      "correct:  6 | estimated:  0 idx:  2118\n",
      "correct:  8 | estimated:  1 idx:  2121\n",
      "correct:  9 | estimated:  2 idx:  2129\n",
      "correct:  4 | estimated:  9 idx:  2130\n",
      "correct:  6 | estimated:  1 idx:  2135\n",
      "correct:  4 | estimated:  9 idx:  2148\n",
      "correct:  1 | estimated:  2 idx:  2182\n",
      "correct:  0 | estimated:  5 idx:  2185\n",
      "correct:  2 | estimated:  3 idx:  2186\n",
      "correct:  9 | estimated:  1 idx:  2189\n",
      "correct:  6 | estimated:  5 idx:  2215\n",
      "correct:  5 | estimated:  6 idx:  2224\n",
      "correct:  1 | estimated:  6 idx:  2266\n",
      "correct:  8 | estimated:  0 idx:  2272\n",
      "correct:  9 | estimated:  6 idx:  2293\n",
      "correct:  2 | estimated:  8 idx:  2299\n",
      "correct:  7 | estimated:  2 idx:  2325\n",
      "correct:  5 | estimated:  9 idx:  2369\n",
      "correct:  4 | estimated:  9 idx:  2371\n",
      "correct:  9 | estimated:  1 idx:  2387\n",
      "correct:  8 | estimated:  3 idx:  2393\n",
      "correct:  4 | estimated:  9 idx:  2394\n",
      "correct:  9 | estimated:  1 idx:  2406\n",
      "correct:  3 | estimated:  9 idx:  2408\n",
      "correct:  9 | estimated:  4 idx:  2414\n",
      "correct:  6 | estimated:  4 idx:  2422\n",
      "correct:  8 | estimated:  3 idx:  2425\n",
      "correct:  2 | estimated:  1 idx:  2433\n",
      "correct:  2 | estimated:  6 idx:  2488\n",
      "correct:  5 | estimated:  3 idx:  2526\n",
      "correct:  3 | estimated:  5 idx:  2534\n",
      "correct:  5 | estimated:  8 idx:  2556\n",
      "correct:  5 | estimated:  8 idx:  2573\n",
      "correct:  7 | estimated:  1 idx:  2578\n",
      "correct:  8 | estimated:  2 idx:  2598\n",
      "correct:  7 | estimated:  1 idx:  2607\n",
      "correct:  2 | estimated:  8 idx:  2610\n",
      "correct:  9 | estimated:  0 idx:  2648\n",
      "correct:  6 | estimated:  1 idx:  2654\n",
      "correct:  7 | estimated:  4 idx:  2730\n",
      "correct:  8 | estimated:  3 idx:  2758\n",
      "correct:  9 | estimated:  4 idx:  2760\n",
      "correct:  3 | estimated:  6 idx:  2770\n",
      "correct:  4 | estimated:  9 idx:  2771\n",
      "correct:  2 | estimated:  3 idx:  2780\n",
      "correct:  5 | estimated:  3 idx:  2810\n",
      "correct:  4 | estimated:  9 idx:  2818\n",
      "correct:  9 | estimated:  4 idx:  2863\n",
      "correct:  8 | estimated:  0 idx:  2896\n",
      "correct:  4 | estimated:  9 idx:  2907\n",
      "correct:  3 | estimated:  0 idx:  2921\n",
      "correct:  5 | estimated:  0 idx:  2925\n",
      "correct:  3 | estimated:  2 idx:  2927\n",
      "correct:  3 | estimated:  5 idx:  2952\n",
      "correct:  3 | estimated:  5 idx:  2953\n",
      "correct:  9 | estimated:  1 idx:  3005\n",
      "correct:  9 | estimated:  7 idx:  3060\n",
      "correct:  8 | estimated:  3 idx:  3062\n",
      "correct:  1 | estimated:  2 idx:  3073\n",
      "correct:  5 | estimated:  3 idx:  3100\n",
      "correct:  4 | estimated:  6 idx:  3114\n",
      "correct:  5 | estimated:  4 idx:  3115\n",
      "correct:  5 | estimated:  9 idx:  3117\n",
      "correct:  6 | estimated:  0 idx:  3130\n",
      "correct:  7 | estimated:  1 idx:  3136\n",
      "correct:  7 | estimated:  4 idx:  3189\n",
      "correct:  8 | estimated:  3 idx:  3206\n",
      "correct:  7 | estimated:  1 idx:  3225\n",
      "correct:  9 | estimated:  3 idx:  3240\n",
      "correct:  7 | estimated:  1 idx:  3262\n",
      "correct:  6 | estimated:  0 idx:  3269\n",
      "correct:  8 | estimated:  9 idx:  3289\n",
      "correct:  7 | estimated:  4 idx:  3316\n",
      "correct:  2 | estimated:  3 idx:  3330\n",
      "correct:  7 | estimated:  9 idx:  3333\n",
      "correct:  7 | estimated:  9 idx:  3376\n",
      "correct:  4 | estimated:  9 idx:  3405\n",
      "correct:  0 | estimated:  8 idx:  3450\n",
      "correct:  4 | estimated:  9 idx:  3490\n",
      "correct:  9 | estimated:  1 idx:  3503\n",
      "correct:  6 | estimated:  4 idx:  3520\n",
      "correct:  3 | estimated:  2 idx:  3549\n",
      "correct:  5 | estimated:  0 idx:  3558\n",
      "correct:  8 | estimated:  5 idx:  3559\n",
      "correct:  5 | estimated:  3 idx:  3565\n",
      "correct:  7 | estimated:  4 idx:  3573\n",
      "correct:  7 | estimated:  8 idx:  3575\n",
      "correct:  7 | estimated:  1 idx:  3580\n",
      "correct:  9 | estimated:  3 idx:  3597\n",
      "correct:  7 | estimated:  0 idx:  3604\n",
      "correct:  8 | estimated:  3 idx:  3674\n",
      "correct:  2 | estimated:  3 idx:  3681\n",
      "correct:  5 | estimated:  3 idx:  3702\n",
      "correct:  9 | estimated:  3 idx:  3716\n",
      "correct:  4 | estimated:  9 idx:  3718\n",
      "correct:  4 | estimated:  9 idx:  3726\n",
      "correct:  7 | estimated:  9 idx:  3730\n",
      "correct:  7 | estimated:  1 idx:  3751\n",
      "correct:  5 | estimated:  3 idx:  3756\n",
      "correct:  4 | estimated:  9 idx:  3758\n",
      "correct:  7 | estimated:  2 idx:  3767\n",
      "correct:  3 | estimated:  9 idx:  3769\n",
      "correct:  5 | estimated:  8 idx:  3776\n",
      "correct:  4 | estimated:  6 idx:  3780\n",
      "correct:  2 | estimated:  8 idx:  3796\n",
      "correct:  6 | estimated:  0 idx:  3801\n",
      "correct:  5 | estimated:  8 idx:  3806\n",
      "correct:  7 | estimated:  9 idx:  3808\n",
      "correct:  2 | estimated:  4 idx:  3811\n",
      "correct:  2 | estimated:  8 idx:  3817\n",
      "correct:  7 | estimated:  1 idx:  3838\n",
      "correct:  6 | estimated:  5 idx:  3853\n",
      "correct:  5 | estimated:  0 idx:  3855\n",
      "correct:  2 | estimated:  3 idx:  3862\n",
      "correct:  9 | estimated:  4 idx:  3869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct:  2 | estimated:  3 idx:  3876\n",
      "correct:  5 | estimated:  6 idx:  3893\n",
      "correct:  5 | estimated:  3 idx:  3902\n",
      "correct:  1 | estimated:  3 idx:  3906\n",
      "correct:  9 | estimated:  3 idx:  3926\n",
      "correct:  4 | estimated:  6 idx:  3941\n",
      "correct:  3 | estimated:  5 idx:  3943\n",
      "correct:  2 | estimated:  8 idx:  3946\n",
      "correct:  7 | estimated:  1 idx:  3976\n",
      "correct:  7 | estimated:  6 idx:  4007\n",
      "correct:  6 | estimated:  5 idx:  4063\n",
      "correct:  0 | estimated:  6 idx:  4065\n",
      "correct:  8 | estimated:  3 idx:  4068\n",
      "correct:  8 | estimated:  0 idx:  4075\n",
      "correct:  9 | estimated:  3 idx:  4078\n",
      "correct:  9 | estimated:  4 idx:  4093\n",
      "correct:  5 | estimated:  1 idx:  4131\n",
      "correct:  8 | estimated:  2 idx:  4140\n",
      "correct:  5 | estimated:  1 idx:  4152\n",
      "correct:  9 | estimated:  4 idx:  4154\n",
      "correct:  8 | estimated:  3 idx:  4159\n",
      "correct:  9 | estimated:  0 idx:  4163\n",
      "correct:  2 | estimated:  6 idx:  4176\n",
      "correct:  7 | estimated:  9 idx:  4199\n",
      "correct:  2 | estimated:  3 idx:  4205\n",
      "correct:  6 | estimated:  5 idx:  4211\n",
      "correct:  1 | estimated:  3 idx:  4212\n",
      "correct:  9 | estimated:  7 idx:  4224\n",
      "correct:  7 | estimated:  9 idx:  4238\n",
      "correct:  2 | estimated:  8 idx:  4248\n",
      "correct:  5 | estimated:  3 idx:  4255\n",
      "correct:  5 | estimated:  3 idx:  4271\n",
      "correct:  2 | estimated:  7 idx:  4289\n",
      "correct:  7 | estimated:  1 idx:  4297\n",
      "correct:  5 | estimated:  8 idx:  4300\n",
      "correct:  3 | estimated:  7 idx:  4306\n",
      "correct:  5 | estimated:  9 idx:  4355\n",
      "correct:  5 | estimated:  8 idx:  4356\n",
      "correct:  5 | estimated:  7 idx:  4359\n",
      "correct:  9 | estimated:  4 idx:  4369\n",
      "correct:  5 | estimated:  6 idx:  4374\n",
      "correct:  9 | estimated:  4 idx:  4425\n",
      "correct:  3 | estimated:  7 idx:  4435\n",
      "correct:  6 | estimated:  0 idx:  4449\n",
      "correct:  2 | estimated:  8 idx:  4451\n",
      "correct:  0 | estimated:  6 idx:  4477\n",
      "correct:  8 | estimated:  7 idx:  4497\n",
      "correct:  9 | estimated:  1 idx:  4500\n",
      "correct:  6 | estimated:  5 idx:  4536\n",
      "correct:  7 | estimated:  3 idx:  4540\n",
      "correct:  4 | estimated:  9 idx:  4567\n",
      "correct:  4 | estimated:  2 idx:  4575\n",
      "correct:  7 | estimated:  9 idx:  4578\n",
      "correct:  8 | estimated:  4 idx:  4601\n",
      "correct:  2 | estimated:  4 idx:  4615\n",
      "correct:  3 | estimated:  5 idx:  4635\n",
      "correct:  8 | estimated:  9 idx:  4639\n",
      "correct:  8 | estimated:  3 idx:  4671\n",
      "correct:  7 | estimated:  2 idx:  4690\n",
      "correct:  4 | estimated:  9 idx:  4695\n",
      "correct:  8 | estimated:  7 idx:  4731\n",
      "correct:  3 | estimated:  9 idx:  4740\n",
      "correct:  4 | estimated:  6 idx:  4751\n",
      "correct:  3 | estimated:  8 idx:  4785\n",
      "correct:  8 | estimated:  0 idx:  4807\n",
      "correct:  6 | estimated:  0 idx:  4814\n",
      "correct:  9 | estimated:  4 idx:  4823\n",
      "correct:  7 | estimated:  1 idx:  4837\n",
      "correct:  4 | estimated:  9 idx:  4860\n",
      "correct:  9 | estimated:  0 idx:  4874\n",
      "correct:  2 | estimated:  4 idx:  4876\n",
      "correct:  8 | estimated:  6 idx:  4879\n",
      "correct:  0 | estimated:  8 idx:  4880\n",
      "correct:  7 | estimated:  1 idx:  4886\n",
      "correct:  2 | estimated:  3 idx:  4950\n",
      "correct:  6 | estimated:  5 idx:  4952\n",
      "correct:  8 | estimated:  4 idx:  4956\n",
      "correct:  7 | estimated:  1 idx:  4966\n",
      "correct:  3 | estimated:  8 idx:  4990\n",
      "correct:  3 | estimated:  2 idx:  5067\n",
      "correct:  3 | estimated:  2 idx:  5078\n",
      "correct:  3 | estimated:  2 idx:  5140\n",
      "correct:  8 | estimated:  4 idx:  5183\n",
      "correct:  4 | estimated:  9 idx:  5201\n",
      "correct:  7 | estimated:  2 idx:  5246\n",
      "correct:  1 | estimated:  6 idx:  5331\n",
      "correct:  1 | estimated:  8 idx:  5457\n",
      "correct:  7 | estimated:  9 idx:  5600\n",
      "correct:  7 | estimated:  9 idx:  5620\n",
      "correct:  2 | estimated:  3 idx:  5634\n",
      "correct:  1 | estimated:  8 idx:  5642\n",
      "correct:  7 | estimated:  9 idx:  5714\n",
      "correct:  3 | estimated:  7 idx:  5734\n",
      "correct:  5 | estimated:  6 idx:  5735\n",
      "correct:  8 | estimated:  6 idx:  5749\n",
      "correct:  5 | estimated:  6 idx:  5752\n",
      "correct:  7 | estimated:  9 idx:  5835\n",
      "correct:  7 | estimated:  4 idx:  5858\n",
      "correct:  7 | estimated:  0 idx:  5887\n",
      "correct:  4 | estimated:  0 idx:  5888\n",
      "correct:  5 | estimated:  3 idx:  5891\n",
      "correct:  7 | estimated:  9 idx:  5906\n",
      "correct:  5 | estimated:  3 idx:  5913\n",
      "correct:  4 | estimated:  9 idx:  5936\n",
      "correct:  5 | estimated:  3 idx:  5937\n",
      "correct:  3 | estimated:  8 idx:  5955\n",
      "correct:  5 | estimated:  3 idx:  5972\n",
      "correct:  3 | estimated:  8 idx:  5973\n",
      "correct:  5 | estimated:  3 idx:  5982\n",
      "correct:  8 | estimated:  9 idx:  6024\n",
      "correct:  2 | estimated:  0 idx:  6035\n",
      "correct:  5 | estimated:  3 idx:  6042\n",
      "correct:  8 | estimated:  3 idx:  6056\n",
      "correct:  3 | estimated:  9 idx:  6059\n",
      "correct:  3 | estimated:  8 idx:  6065\n",
      "correct:  9 | estimated:  3 idx:  6071\n",
      "correct:  9 | estimated:  3 idx:  6081\n",
      "correct:  9 | estimated:  3 idx:  6091\n",
      "correct:  9 | estimated:  3 idx:  6166\n",
      "correct:  9 | estimated:  0 idx:  6172\n",
      "correct:  8 | estimated:  6 idx:  6347\n",
      "correct:  5 | estimated:  8 idx:  6390\n",
      "correct:  2 | estimated:  6 idx:  6391\n",
      "correct:  5 | estimated:  2 idx:  6392\n",
      "correct:  0 | estimated:  6 idx:  6400\n",
      "correct:  3 | estimated:  2 idx:  6421\n",
      "correct:  0 | estimated:  6 idx:  6426\n",
      "correct:  9 | estimated:  0 idx:  6505\n",
      "correct:  8 | estimated:  9 idx:  6555\n",
      "correct:  9 | estimated:  4 idx:  6568\n",
      "correct:  9 | estimated:  7 idx:  6571\n",
      "correct:  7 | estimated:  1 idx:  6577\n",
      "correct:  0 | estimated:  7 idx:  6597\n",
      "correct:  8 | estimated:  9 idx:  6603\n",
      "correct:  8 | estimated:  4 idx:  6625\n",
      "correct:  0 | estimated:  5 idx:  6651\n",
      "correct:  5 | estimated:  9 idx:  6706\n",
      "correct:  4 | estimated:  8 idx:  6769\n",
      "correct:  2 | estimated:  4 idx:  6785\n",
      "correct:  6 | estimated:  4 idx:  6926\n",
      "correct:  5 | estimated:  6 idx:  6981\n",
      "correct:  0 | estimated:  6 idx:  7049\n",
      "correct:  8 | estimated:  9 idx:  7094\n",
      "correct:  8 | estimated:  9 idx:  7121\n",
      "correct:  7 | estimated:  1 idx:  7432\n",
      "correct:  4 | estimated:  8 idx:  7434\n",
      "correct:  5 | estimated:  8 idx:  7451\n",
      "correct:  5 | estimated:  3 idx:  7498\n",
      "correct:  2 | estimated:  8 idx:  7539\n",
      "correct:  2 | estimated:  3 idx:  7637\n",
      "correct:  5 | estimated:  8 idx:  7732\n",
      "correct:  5 | estimated:  6 idx:  7797\n",
      "correct:  5 | estimated:  8 idx:  7842\n",
      "correct:  3 | estimated:  9 idx:  7849\n",
      "correct:  5 | estimated:  6 idx:  7850\n",
      "correct:  3 | estimated:  2 idx:  7858\n",
      "correct:  2 | estimated:  4 idx:  7886\n",
      "correct:  3 | estimated:  2 idx:  7905\n",
      "correct:  2 | estimated:  4 idx:  7917\n",
      "correct:  2 | estimated:  6 idx:  7945\n",
      "correct:  1 | estimated:  8 idx:  8020\n",
      "correct:  5 | estimated:  8 idx:  8062\n",
      "correct:  4 | estimated:  6 idx:  8081\n",
      "correct:  2 | estimated:  1 idx:  8091\n",
      "correct:  2 | estimated:  8 idx:  8094\n",
      "correct:  6 | estimated:  0 idx:  8196\n",
      "correct:  3 | estimated:  7 idx:  8246\n",
      "correct:  2 | estimated:  0 idx:  8318\n",
      "correct:  8 | estimated:  6 idx:  8339\n",
      "correct:  4 | estimated:  9 idx:  8406\n",
      "correct:  8 | estimated:  6 idx:  8408\n",
      "correct:  8 | estimated:  6 idx:  8410\n",
      "correct:  5 | estimated:  8 idx:  8453\n",
      "correct:  4 | estimated:  9 idx:  8520\n",
      "correct:  8 | estimated:  6 idx:  8522\n",
      "correct:  2 | estimated:  3 idx:  8584\n",
      "correct:  2 | estimated:  3 idx:  8639\n",
      "correct:  5 | estimated:  6 idx:  8863\n",
      "correct:  7 | estimated:  2 idx:  9009\n",
      "correct:  2 | estimated:  8 idx:  9010\n",
      "correct:  7 | estimated:  2 idx:  9015\n",
      "correct:  0 | estimated:  5 idx:  9016\n",
      "correct:  7 | estimated:  2 idx:  9019\n",
      "correct:  7 | estimated:  2 idx:  9024\n",
      "correct:  7 | estimated:  2 idx:  9036\n",
      "correct:  7 | estimated:  2 idx:  9045\n",
      "correct:  2 | estimated:  8 idx:  9209\n",
      "correct:  8 | estimated:  5 idx:  9280\n",
      "correct:  8 | estimated:  3 idx:  9316\n",
      "correct:  5 | estimated:  3 idx:  9482\n",
      "correct:  9 | estimated:  4 idx:  9587\n",
      "correct:  0 | estimated:  8 idx:  9634\n",
      "correct:  9 | estimated:  7 idx:  9642\n",
      "correct:  3 | estimated:  2 idx:  9655\n",
      "correct:  6 | estimated:  3 idx:  9679\n",
      "correct:  6 | estimated:  5 idx:  9698\n",
      "correct:  2 | estimated:  0 idx:  9716\n",
      "correct:  5 | estimated:  0 idx:  9719\n",
      "correct:  5 | estimated:  6 idx:  9729\n",
      "correct:  8 | estimated:  1 idx:  9744\n",
      "correct:  4 | estimated:  2 idx:  9745\n",
      "correct:  5 | estimated:  6 idx:  9749\n",
      "correct:  2 | estimated:  0 idx:  9751\n",
      "correct:  2 | estimated:  0 idx:  9752\n",
      "correct:  2 | estimated:  0 idx:  9768\n",
      "correct:  5 | estimated:  0 idx:  9770\n",
      "correct:  5 | estimated:  0 idx:  9777\n",
      "correct:  2 | estimated:  0 idx:  9779\n",
      "correct:  4 | estimated:  9 idx:  9792\n",
      "correct:  9 | estimated:  4 idx:  9808\n",
      "correct:  2 | estimated:  8 idx:  9811\n",
      "correct:  2 | estimated:  7 idx:  9839\n",
      "correct:  6 | estimated:  8 idx:  9858\n",
      "correct:  2 | estimated:  8 idx:  9867\n",
      "correct:  0 | estimated:  6 idx:  9879\n",
      "correct:  5 | estimated:  1 idx:  9883\n",
      "correct:  2 | estimated:  8 idx:  9893\n",
      "correct:  3 | estimated:  9 idx:  9905\n",
      "correct:  3 | estimated:  8 idx:  9925\n",
      "correct:  5 | estimated:  3 idx:  9941\n",
      "correct:  3 | estimated:  9 idx:  9944\n",
      "correct:  5 | estimated:  3 idx:  9970\n",
      "correct:  3 | estimated:  2 idx:  9975\n",
      "correct:  5 | estimated:  6 idx:  9982\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "\n",
    "num_input = 784\n",
    "num_hidden = 100\n",
    "num_output = 10\n",
    "learning_rate = 0.03\n",
    "\n",
    "NN = NeuralNetwork2(num_input, num_hidden, num_output, learning_rate);\n",
    "for epoch in range(epochs):\n",
    "    print(\"epoch: \", epoch)\n",
    "    for example in training_data_set:\n",
    "        label = np.zeros(10) + 0.01\n",
    "        label[int(example[0])] = .99\n",
    "        training_example = np.asfarray(example.split(',')[1:])\n",
    "        training_example /= 255.\n",
    "        training_example *= .99\n",
    "        training_example += 0.01\n",
    "        NN.train(training_example, label)\n",
    "idx = 0\n",
    "for example in testing_data_set:\n",
    "    label = np.zeros(10) + 0.01\n",
    "    label[int(example[0])] = .99\n",
    "    testing_example = np.asfarray(example.split(',')[1:])\n",
    "    testing_example /= 255.\n",
    "    testing_example *= .99\n",
    "    testing_example += 0.01\n",
    "    if(np.argmax(NN.query(testing_example)) != int(example[0])) :\n",
    "        print(\"correct: \", example[0], \"| estimated: \", np.argmax(NN.query(testing_example)), \"idx: \", idx)\n",
    "    idx += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct answer:  4\n",
      "estimated:  6\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x264b4605d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "testing_example = np.asfarray(testing_data_set[1549].split(',')[1:])\n",
    "print(\"correct answer: \", testing_data_set[1549][0])\n",
    "print(\"estimated: \", np.argmax(NN.query(testing_example)))\n",
    "plt.imshow(testing_example.reshape(28,28), cmap=\"Greys\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
